{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad25035d-7038-499a-8033-4fdbce497944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871e0137-9d66-4d59-95c1-71a865e20b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "pad_sequences =  tf.keras.preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d66471-5356-4f00-bc0a-95cdbcbf5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=(open(\"documents.txt\").read())\n",
    "corpus = text.lower()\n",
    "corpus = corpus.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c604ee-2c32-4585-a032-4c367964e485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b6e4cf-2b0a-40a2-bb62-2fcf877048b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8b7f6e-10cb-4912-9a99-6576ddb0ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "108a1ad9-22db-4e65-a14f-be5bb9c5f0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9f038f-d00d-484f-9140-cd40d6764397",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1969ab96-8f2f-4b1e-b413-920e3289fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_seqs.append(n_gram_sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ae91ec7-b818-4c77-ab54-8b5034ec3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(x) for x in input_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e467b2-66eb-421b-b33c-1502297165f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = np.array(pad_sequences(input_seqs, maxlen = max_seq_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8731076-b746-414b-a88c-77ebf4a78033",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = input_seqs[:, :-1]\n",
    "ys = input_seqs[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064674fd-4304-4e7c-a388-ad7379d24291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.keras.utils.to_categorical(ys, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406c5422-fed7-44ca-90f2-c39b4e10bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca4bd45d-ee4c-4a13-b71f-9b4e1a6dd579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halluru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Embedding(total_words, 240, input_length=max_seq_len-1))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)))\n",
    "model.add(tf.keras.layers.Dense(total_words, activation='softmax'))\n",
    "adam = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad2b0a36-2116-4a87-9cca-acb101db1035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 69, 240)           94560     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300)              469200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 394)               118594    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 682,354\n",
      "Trainable params: 682,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d62b0c7-36e6-4eb4-b879-f0e367f56d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 18s 213ms/step - loss: 5.4728 - accuracy: 0.0651\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 10s 212ms/step - loss: 4.5252 - accuracy: 0.1488\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 3.3708 - accuracy: 0.2719\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 2.3028 - accuracy: 0.4311\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 10s 207ms/step - loss: 1.4138 - accuracy: 0.6198\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 10s 206ms/step - loss: 0.7899 - accuracy: 0.7951\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 10s 206ms/step - loss: 0.4704 - accuracy: 0.8808\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 10s 206ms/step - loss: 0.2810 - accuracy: 0.9349\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 10s 212ms/step - loss: 0.1859 - accuracy: 0.9504\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 0.1481 - accuracy: 0.9601\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 0.1223 - accuracy: 0.9652\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 0.1169 - accuracy: 0.9633\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 0.1079 - accuracy: 0.9691\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 0.1080 - accuracy: 0.9639\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 0.1036 - accuracy: 0.9652\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 0.1032 - accuracy: 0.9639\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 11s 219ms/step - loss: 0.0980 - accuracy: 0.9671\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 0.0993 - accuracy: 0.9659\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 0.1007 - accuracy: 0.9652\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 0.0971 - accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xs, ys, epochs = 20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1668e757-2113-4729-97e1-4c49686f3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000020917D69660> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000020917D69F90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ef1e63-dc50-4715-8deb-a9ab3c87faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a933b500-97dd-4330-ad23-d4cfc0e281af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(seed_text):\n",
    "\n",
    "    next_words = 20\n",
    "    next_text = ''\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        seed_text = seed_text.lower()\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "        #predicted = model.predict_classes(token_list, verbose=0)\n",
    "        predict_x=model.predict(token_list, verbose=0)\n",
    "        predicted = np.argmax(predict_x,axis=1)\n",
    "        out = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                out = word\n",
    "                break\n",
    "        seed_text += \" \" +out\n",
    "    return seed_text\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed7c7b30-c478-49e1-89b8-60fea6052455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the if are available sites are available if the multisite concepts are activated in the multisite concepts activation tcemm4600m000 workbench session a site is linked'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('the if are available sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d57a8b-fb50-4c52-a802-fb7b4dc4404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    words = sentence.split(' ')\n",
    "    words = [i for i in words if i != 'undefined']\n",
    "    final_words = words[::-1]\n",
    "    final = ' '.join(final_words)\n",
    "    print(final)\n",
    "    output = generate(final)\n",
    "    output.replace('  ', ' ')\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "876aa277-8bfa-4240-87d0-5e037c316e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def response(msg):\n",
    "    output = predict_class(msg, model)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41feb90-1d26-48dc-8572-b1fcd785ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b52f51-f712-46cd-908e-79c6e85a41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_corrections(text):\n",
    "    words = text.split()\n",
    "    corrected = []\n",
    "    for word in words:\n",
    "        pred = spelling.suggest(word)[0][0]\n",
    "        if pred !=word:\n",
    "            corrected.append(word + ' --> ' + spelling.suggest(word)[0][0])\n",
    "        #corrected = corrected +\" \"+ spelling.suggest(i)[0][0] # Spell checking word by word\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50d9ca-b960-406f-b38c-12ca86642d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [31/May/2022 14:49:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:49:26] \"GET /swaggerui/droid-sans.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [31/May/2022 14:49:26] \"GET /swaggerui/swagger-ui-standalone-preset.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [31/May/2022 14:49:26] \"GET /swaggerui/swagger-ui-bundle.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [31/May/2022 14:49:26] \"GET /swaggerui/swagger-ui.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [31/May/2022 14:49:26] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:49:27] \"GET /swaggerui/favicon-32x32.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:51:15] \"OPTIONS /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 14:51:17] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites are  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 14:51:21] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:51:22] \"OPTIONS /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites are availble  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 14:51:24] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:51:24] \"OPTIONS /check HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:51:24] \"POST /check HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites are availble \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 14:51:27] \"OPTIONS /generate_html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 14:51:28] \"POST /generate_html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:10:04] \"OPTIONS /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 15:10:06] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites are  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 15:10:11] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:10:30] \"OPTIONS /check HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:10:30] \"POST /check HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites are availble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 15:11:01] \"OPTIONS /generate_html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:11:02] \"POST /generate_html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:11:19] \"OPTIONS /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>\n",
      "sites are availble \n",
      "<p> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 15:11:23] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:11:29] \"OPTIONS /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>\n",
      "sites are availble are \n",
      "<p> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 15:11:33] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:11:45] \"OPTIONS /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are availble are sdpoas \n",
      "<p> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/May/2022 15:11:48] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:11:56] \"OPTIONS /generate_html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/May/2022 15:11:56] \"POST /generate_html HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from flask import Flask, request\n",
    "from flask_cors import CORS\n",
    "from flask_restx import Resource, Api, fields\n",
    "import sys\n",
    "import webbrowser\n",
    "\n",
    "## Modules and requirements for Corrections\n",
    "from textblob.en import Spelling        \n",
    "from textblob import TextBlob\n",
    "\n",
    "pathToFile = \"train.txt\" \n",
    "spelling = Spelling(path = pathToFile)\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)                 #  Create a Flask WSGI application\n",
    "CORS(app)\n",
    "api = Api(app)                         #  Create a Flask-RESTPlus API\n",
    "\n",
    "\n",
    "insert_mtdoc = api.model(\n",
    "    \"Insert_user_data\",\n",
    "    {\n",
    "         \"text\": fields.String(description=\"Your text\", required=True)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "@api.route('/generate')\n",
    "class MtDoc(Resource):\n",
    "    @api.expect(insert_mtdoc)\n",
    "    def post(self):\n",
    "        text = request.json['text']\n",
    "        return response(text)\n",
    "    \n",
    "@api.route('/generate_html')\n",
    "class MtDocHtml(Resource):\n",
    "    @api.expect(insert_mtdoc)\n",
    "    def post(self):\n",
    "        text = request.json['text']\n",
    "        f = open('generated.html','w')\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        webbrowser.open_new_tab('generated.html')\n",
    "        \n",
    "@api.route('/check')\n",
    "class MtDocCheck(Resource):\n",
    "    @api.expect(insert_mtdoc)\n",
    "    def post(self):\n",
    "        text = request.json['text']\n",
    "        print(text)\n",
    "        return check_corrections(text)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8fd85-4782-4e56-86b7-c59f647b89c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb58af-8f3d-4e54-9af0-a62cd00a4dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
